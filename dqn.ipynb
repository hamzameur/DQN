{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dqn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WkFC3kN6hjy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc7a7392-87e9-40ae-eee7-93dfeba76da3"
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from cv2 import resize, INTER_CUBIC\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, Activation\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.initializers import RandomNormal\n",
        "from time import time, sleep\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcjdM9HM6t1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env_name = \"AirRaid-v0\"\n",
        "\n",
        "env = gym.make(env_name)\n",
        "s0 = env.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLQucz1oEX3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "5cdc1a58-171a-470b-ae88-bb8138b9ab30"
      },
      "source": [
        "plt.imshow(s0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0b6e54feb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALcAAAD8CAYAAAA18TUwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0nK4LS2H29JyuC0th9vScrgtLYfb0vo/5UqCz2SSfvYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH4mDduq8b50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gamma = 0.99 # discount factor\n",
        "max_epsilon = 1 # initial exploration rate\n",
        "min_epsilon = 0.1 # minimum exploration rate\n",
        "Na = env.action_space.n # environment number of possible actions\n",
        "\n",
        "img_size = (84, 84)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RmxkBbv9z-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class replay_buffer:\n",
        "  def __init__(self, N):\n",
        "    self.N      = N # N is the buffer size\n",
        "    self.buffer = []\n",
        "    \n",
        "  def add_transition(self, s1, a, r, s2, done):\n",
        "    if len(self.buffer)<self.N:\n",
        "      self.buffer.append((s1, a, r, s2, done))\n",
        "    \n",
        "    else:\n",
        "      self.buffer.remove(self.buffer[0])\n",
        "      self.buffer.append((s1, a, r, s2, done))\n",
        "  \n",
        "  def sample_batch(self, bsize):\n",
        "    indices = np.random.choice(len(self.buffer), bsize, replace = False)\n",
        "    \n",
        "    states     = []\n",
        "    actions    = []\n",
        "    rewards    = []\n",
        "    new_states = []\n",
        "    dones      = []\n",
        "    \n",
        "    for ind in indices:\n",
        "      state1   = self.buffer[ind][0]\n",
        "      action   = self.buffer[ind][1]\n",
        "      reward   = self.buffer[ind][2]\n",
        "      state2   = self.buffer[ind][3]\n",
        "      done     = self.buffer[ind][4]\n",
        "      \n",
        "      states.append(state1)\n",
        "      actions.append(action)\n",
        "      rewards.append(reward)\n",
        "      new_states.append(state2)\n",
        "      dones.append(done)\n",
        "      \n",
        "    return states, actions, rewards, new_states, dones"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8UVajfVd3m3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_model:\n",
        "  def __init__(self, Na):\n",
        "    self.q_network = self.create_network(Na)\n",
        "    self.target_network = self.create_network(Na)\n",
        "    self.update_target_network()\n",
        "    \n",
        "    \n",
        "  def create_network(self, Na):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, 8, strides=4, data_format=\"channels_last\", activation=\"relu\", kernel_initializer=RandomNormal(stddev=1e-03), input_shape = (84, 84, 4))) \n",
        "    model.add(Conv2D(32, 4, strides=2, data_format=\"channels_last\", activation=\"relu\", kernel_initializer=RandomNormal(stddev=1e-03)))\n",
        "    model.add(Flatten())\n",
        "    Dense(256, activation=\"relu\", kernel_initializer=RandomNormal(stddev=1e-06))\n",
        "    model.add(Dense(256, activation=\"relu\", kernel_initializer=RandomNormal(stddev=1e-03)))\n",
        "    model.add(Dense(Na, kernel_initializer=RandomNormal(stddev=1e-03)))\n",
        "    model.compile(loss='mse',optimizer=RMSprop(lr=1e-03))\n",
        "    return model\n",
        "    \n",
        "  def train_q_network_on_batch(self, states, q_values):\n",
        "    self.q_network.fit(x = states, y = q_values, epochs = 2, batch_size = len(states), verbose = 0)\n",
        "    \n",
        "  def update_target_network(self):\n",
        "    self.target_network.set_weights(self.q_network.get_weights())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkEa2awswwT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "d3a8905f-1019-4bc3-ec23-0276b08e0efa"
      },
      "source": [
        "dqn = DQN_model(Na)\n",
        "RB = replay_buffer(1e06)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0701 20:54:25.534014 139688155309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0701 20:54:25.551470 139688155309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0701 20:54:25.554687 139688155309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "W0701 20:54:25.631500 139688155309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0701 20:54:25.727307 139688155309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0701 20:54:25.728711 139688155309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe_fygV_w6jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_episodes = 1000 # number of training episodes\n",
        "max_steps = 1000 # maximum number of steps in a training episode\n",
        "update_targets_every = 100 # steps to update the target network "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pQXG-myIRqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_action(state, epsilon):\n",
        "  u = np.random.rand()\n",
        "  \n",
        "  if u < epsilon:\n",
        "    return np.random.choice(Na)\n",
        "    \n",
        "  pred = dqn.q_network.predict(np.array([state]))\n",
        "  \n",
        "  return np.argmax(pred.reshape(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqGN07YTSoOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_obs(obs1, obs2, first):\n",
        "  resized1 = resize(obs1, dsize=img_size, interpolation=INTER_CUBIC)\n",
        "  gray1 = resized1.mean(axis = 2)\n",
        "  \n",
        "  resized2 = resize(obs2, dsize=img_size, interpolation=INTER_CUBIC)\n",
        "  gray2 = resized2.mean(axis = 2)\n",
        "  \n",
        "  if first:\n",
        "    return np.stack([gray1, gray1, gray1, gray1], axis = 2), np.stack([gray1, gray1, gray1, gray2], axis = 2)\n",
        "  \n",
        "  state = RB.buffer[-1][0].copy()\n",
        "  state[:,:,:3] = state[:,:,1:]\n",
        "  state[:,:,-1] = gray1\n",
        "  \n",
        "  \n",
        "  next_state = state.copy()\n",
        "  next_state[:,:,:3] = next_state[:,:,1:]\n",
        "  next_state[:,:,-1] = gray2\n",
        "  \n",
        "  return state, next_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9aonW1sGXUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decay_epsilon(step):\n",
        "  return max(max_epsilon - 9*10**(-7)*step, min_epsilon)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEHaPC_xNZY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "66cb14eb-8530-4a37-99a7-b353738385d7"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "step = 0\n",
        "for episode in range(n_episodes):\n",
        "  total_reward = 0\n",
        "  obs = env.reset()\n",
        "  first = True\n",
        "  state, _ = preprocess_obs(obs, obs, first)\n",
        "  \n",
        "  for episode_step in range(max_steps):\n",
        "    \n",
        "    epsilon = decay_epsilon(step)\n",
        "    \n",
        "    action = choose_action(state, epsilon)\n",
        "    \n",
        "    new_obs, reward, done, _ = env.step(action)\n",
        "    \n",
        "    total_reward += reward\n",
        "    \n",
        "    state, new_state = preprocess_obs(obs, new_obs, first)\n",
        "    \n",
        "    RB.add_transition(state, action, reward, new_state, done)\n",
        "    \n",
        "    n_samples = min(len(RB.buffer), batch_size)\n",
        "    \n",
        "    states, actions, rewards, new_states, dones = RB.sample_batch(bsize = n_samples)\n",
        "    \n",
        "    target_q_vals = dqn.target_network.predict(np.array(states))\n",
        "    \n",
        "    for i in range(n_samples):\n",
        "      if dones[i]:\n",
        "        target_q_vals[i, actions[i]] = rewards[i]\n",
        "        \n",
        "      else:\n",
        "        temp = dqn.target_network.predict(np.array([new_states[i]]))\n",
        "        target_q_vals[i, actions[i]] = rewards[i] + gamma*np.amax(temp)\n",
        "        \n",
        "    dqn.train_q_network_on_batch(np.array(states), target_q_vals)\n",
        "    \n",
        "    if step>0 and step%update_targets_every==0:\n",
        "      dqn.update_target_network()\n",
        "      \n",
        "      \n",
        "    \n",
        "    obs = new_obs\n",
        "    \n",
        "    first = False\n",
        "    \n",
        "    step += 1\n",
        "    if done or (episode_step == max_steps - 1):\n",
        "      print(\"Episode {} / {} : steps = {} , total reward = {}\".format(episode, n_episodes, episode_step, total_reward))\n",
        "      if done:\n",
        "        break\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 0 / 1000 : steps = 387 , total reward = 375.0\n",
            "Episode 1 / 1000 : steps = 801 , total reward = 325.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkgX9dj7N6Hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqn.q_network.save(\"q.h5\")\n",
        "dqn.target_network.save(\"taget.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}